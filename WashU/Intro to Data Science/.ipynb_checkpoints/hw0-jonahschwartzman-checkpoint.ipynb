{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw0.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hw0: What is DS and Intro To Python üêç"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Name:Jonah Schwartzman\n",
    "\n",
    "Student ID:501556\n",
    "\n",
    "Collaborators:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "For this homework, work through **Lab 0 (Introduction to Python)** first. Most of the things we ask you to do in this homework are explained in the lab. In general, you should feel free to import any package(s) that we have previously used in class. **IMPORTANT:** Ensure that all plots have the necessary components that a plot should have: axes labels and a title (and a legend when it is appropriate). You must have all components of a plot on every plot for the entire semester!\n",
    "\n",
    "Frequently **save** your notebook!\n",
    "\n",
    "### Collaborators and Sources\n",
    "Furthermore, in addition to recording your **collaborators** on this homework, please also remember to **cite/indicate all external sources** used when finishing this assignment. \n",
    "> This includes peers, TAs, and links to online sources. \n",
    "\n",
    "Note that these citations will be taken into account during the grading and regrading process, **especially** when two or more submissions closely resemble each other. Working with each other is ok, as long as you cite who you worked with!\n",
    "\n",
    "### Submission instructions\n",
    "* Submit this Python notebook, including your answers and code outputs in the code cells to Gradescope.\n",
    "* [Optional] Commit and push to your Github repo!\n",
    "* **Do not change the number of cells!** Your submission notebook should have exactly one code cell per problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Data Science?\n",
    "\n",
    "In the first lecture, we explored and discussed what data science is..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 1.1\n",
    "\n",
    "**Write-up!** What is data science? Answer this question in your _own_ words by summarizing the main conclusions/definition(s) from your group discussion from the first lecture. Do not cite any definitions of data science you find online or in the course slides. (If you did not attend the first lecture, come up with your _own_ answer to this question now without looking up any defeinitins online.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data science is the study of interpreting and using data for different purposes.  Data science includes the acts of collecting data, expressing the data, and interpreting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Data Science Use Cases\n",
    "Data science is about using data to **find solutions** for a particular problem. Consider the following data science use cases: \n",
    "\n",
    "* automated image captions\n",
    "* crime: predicting locations\n",
    "* crop-yield improvment\n",
    "* diagnosing heart disease\n",
    "* emotion detection\n",
    "* fitness tracking\n",
    "* humane genome sequencing\n",
    "* insurance pricing\n",
    "* language translation\n",
    "* personalized medicine\n",
    "* smart homes\n",
    "* ride sharing\n",
    "* social analytics\n",
    "* terrorist attack prevention\n",
    "\n",
    "\n",
    "### Problem 1.2\n",
    "\n",
    "**Write-up!** From the use cases above, pick one of them and \n",
    "* describe the use case, \n",
    "* the data that is involved, and \n",
    "* how a data scientist might approach and solve the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 1.3\n",
    "\n",
    "**Write-up!** From the use cases above, pick *another one* and \n",
    "* describe the use case, \n",
    "* the data that is involved, and \n",
    "* how a data scientist might approach and solve the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 1.4\n",
    "\n",
    "**Write-up!** Name and briefly describe (one sentence is enough) **two** other data science use cases **not** listed above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 2. Some Python Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some coding problems in this class, we use a tool called otter-grader. This automatically checks the correctness of some elements of your code, and shows you some test cases you can use to assist in your development of a solution. \n",
    "\n",
    "Please note that this **is not** all encompassing and that many questions will **also** be graded for style, or have hidden tests that you cannot see! These questions will be marked with a note saying \"*Note: This question is graded on more than public tests alone*\". \n",
    "\n",
    "For example, the public test for the next question checks if your new string is shorter than the original, and the hidden test checks if your answer matches the intended solution. These public tests tell you what they are looking for if you fail them, so they're used to **guide** you to the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1 \n",
    "\n",
    "**Do this!** Get all but the first four characters of the following string without counting its length: \\\n",
    "*Note: This question is graded on more than public tests alone.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_string = \"This is a really long string and you have now clue on how long it is!\"\n",
    "\n",
    "shorter_string = my_string[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2a</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2a results: All test cases passed!"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2\n",
    "\n",
    "Get the second to fourth elements of `a_list` (reminder: the first element of a list is not index 1, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_list = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "new_list = a_list[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2b</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2b results: All test cases passed!"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.3\n",
    "\n",
    "In this problem we will get some more practice using the most common syntax constructs in Python, specifically _control flow_ and _for loops_. To do this, we will tackle the notorious \"FizzBuzz\" question that pops up on coding assessments sometimes.\n",
    "\n",
    "**Do this!** Complete the following function so that it returns a sequence of numbers 1 through n, where `n` is an argument. However, for each multiple of 3, add \"Fizz\" instead of the number, for each multiple of 5, add \"Buzz\" instead of the number, and for numbers which are multiples of both 3 and 5, add \"FizzBuzz\" instead of the number. We will check your solution for you as you go ‚Äî try \"running\" (‚ñ∂Ô∏è or `shift + enter`) the cell below and take a look at the output.\n",
    "\n",
    "*Note: This question is graded on more than public tests alone*\n",
    "\n",
    "> **Hint**: Start by creating a for loop to add every even number in the interval `[1:n]` to a list; you'll need to create an appropriate `iterable` first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fizzbuzz(n):\n",
    "    '''\n",
    "    Returns a sequence of numbers 1 through, and including, N, except when the number\n",
    "    is a multiple of 3, 5 or of both. In these cases, the sequence entry shoudl be \"Fizz\",\n",
    "    \"Buzz\", and \"FizzBuzz\", respectively. Return the sequence as a list. \n",
    "    \n",
    "    >>> fizzbuzz(5)\n",
    "    \n",
    "    [1, 2, 'Fizz', 4, 'Buzz']\n",
    "    '''\n",
    "    \n",
    "    sequence = []\n",
    "    ...\n",
    "    return sequence\n",
    "\n",
    "fizzbuzz(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.4\n",
    "\n",
    "A _hailstone sequence_ is a fun little sequence that starts with a positive _integer_ $n$. Then,\n",
    "1. if $n$ is even, divide it by 2\n",
    "2. if $n$ is odd, multiply it by 3 and add 1\n",
    "3. continue this process until $n$ is 1.\n",
    "\n",
    "**Do this!** Complete the following function so that it creates a list of the hailstone sequence starting at integer `n`. It should also include `n` itself. _**Hint**: use floor division `//` to get integers when dividing. Also, if you run into infinite loops, hit `Kernel > Interrupt Kernel` in the top bar._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hailstone(n):\n",
    "    '''\n",
    "    Returns a list of the hailstone sequence starting with n.\n",
    "    \n",
    "    >>> hailstone(10)\n",
    "    [10, 5, 16, 8, 4, 2, 1]\n",
    "    '''\n",
    "    \n",
    "    sequence = []\n",
    "    ...\n",
    "    return sequence\n",
    "    \n",
    "hailstone(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.5\n",
    "\n",
    "**Do this!** Use an appropriate function with a lambda function as its input to find the student with the soonest graduation date. Assign the result to the variable `soonest_grad_date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roster = [\n",
    "    ['Billy',  21, 2024],\n",
    "    ['Meghan', 18, 2023],\n",
    "    ['Jeff',   21, 2021],\n",
    "    ['Alex',   50, 2024],\n",
    "    ['Cate',   21, 2023]\n",
    "]\n",
    "\n",
    "soonest_grad_date = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Timing Comparison\n",
    "\n",
    "There were some questions about why we emphasize NumPy functions and indexing so intensely. To help explain and motivate this, let's do some performance comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run me!\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment, we will be testing various operations with random arrays. Here is an example of how you can generate a random array using `np.random.rand`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.1\n",
    "\n",
    "**Do this!** Complete the function below so that it returns a random array of size `n`. Assign your new array to the `result` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_random_array(n):\n",
    "    '''Returns a random array of a given shape.'''\n",
    "    \n",
    "    result = ...\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out! You should see an array similar to the one from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_random_array(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Summing Arrays\n",
    "\n",
    "Let's try a sum operation. There are two ways of computing the sum of an array using built-in features. The first is to use a `for` loop and iterate through the values in an array. The second is to use the `sum` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.2\n",
    "\n",
    "**Implement this!** Complete the function below so that it returns the sum of an array `a`, making sure to use a `for` loop. Again, assign your result to the `result` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loop_sum(a):\n",
    "    '''Computes the sum of array A using a for loop'''\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 3.3\n",
    "\n",
    "Now that we have a working `for` loop sum implementation, `loop_sum`, let's compare its performance to both the Python built-in `sum` function and the NumPy `np.sum` function. \n",
    "> We will use an [IPython magic command üßô‚Äç‚ôÄÔ∏è](https://ipython.readthedocs.io/en/stable/interactive/tutorial.html#magic-functions) (I'm not kidding) called `%timeit`. This function will run a given command repeatedly and report back the mean runtime and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_array = generate_random_array(10000)\n",
    "\n",
    "%timeit loop_sum(another_array)\n",
    "%timeit sum(another_array)\n",
    "%timeit np.sum(another_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write up!** Let's study this output. Answer the following questions: \n",
    "1. Which way of implementing the sum is most efficient?\n",
    "2. How much faster is the most efficient way of computing the sum compared to the other implementations?  \n",
    "3. What would happen if you added more dimensions to your array (think _analyzing a much bigger dataset_)? \n",
    "4. What do these results tell us in terms of implementing solutions to data sceince problems?\n",
    "5. Assume that the fastest way of implemeting the sum would take 1 minute. How much time would it take to compute the result using the other implementations? Report your result in hours. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### 3.2 Finding a Value\n",
    "\n",
    "In Problem 2 we needed to find the age and class of the student from a roster who would graduate first. Let's use this set up to do another comparison. Here is the data that we worked with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Billy','Meghan','Jeff','Alex','Cate']\n",
    "roster = np.array([\n",
    "    [21, 2021],\n",
    "    [18, 2020],\n",
    "    [21, 2019],\n",
    "    [50, 2021],\n",
    "    [21, 2020]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we used the Python built-in `min` function with a lambda to accomplish this for a `List` version of the roster. What would happen if we had used the same method to do the same for a NumPy array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(roster, key=lambda student: student[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An appropriate NumPy equivalent of the code is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roster[np.argmin(roster[:, 1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the student's name by doing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names[np.argmin(roster[:, 1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Problem 3.4\n",
    "\n",
    "Before we check out the performance of each of these implementations, let's expand our roster a bit. In the following cell, we generate a new roster with entries for 1000 students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roster = np.array([np.random.randint(16, 100, size=1000),\n",
    "                   np.random.randint(2018, 2022, size=1000)]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a preview of the new roster containing the first ten rows in the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roster[:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to evaluate these implementations using the `%timeit` magic command from earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit min(roster, key=lambda student: student[1])\n",
    "%timeit roster[np.argmin(roster[:, 1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write up!** Let's study this output by answering the following questions: \n",
    "1. Which way of implementing the information retrieval is most efficient?\n",
    "2. How much faster is the more efficient computation compared to the slower implementation?  \n",
    "3. What would happen if you added more dimensions to your array (think _analyzing a much bigger dataset_)? \n",
    "4. What do these results tell us in terms of using Python versus NumPy bulit-in functions in solutions to data sceince problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 4. Images are Arrays!\n",
    "\n",
    "AKA, more [NumPy](https://numpy.org) practice ‚Äî so exciting, right? In this problem we will expand on the generality of NumPy's arrays; specifically, we will be looking at how we can think of images as arrays of pixel values.\n",
    "\n",
    "But first, let's just do a quick review of some basic operations with NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.1\n",
    "\n",
    "**Do this!** Create a three dimensional array of ones with shape $3 \\times 3 \\times 2$ and assign it to a variable called `ones_array`. _**Hint**:_ you can view the resulting array by evaluating the variable (write the name on its own line at the end of the cell; remember that only the value of the last expression in the cell will be displayed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ones_array = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Time!\n",
    "\n",
    "This will be the image we are working with today.\n",
    "\n",
    "Without getting too technical, digital images are composed of pixels arranged in a rectangular grid. Each pixel has an intensity value within some range (between 0 and 1 in this case) that specifies how dark or light it should be. Shades of gray (in a black and white image) can be specified by a single value whereas colors are typically specified by a tuple of three values (see the [RGB color model](https://en.wikipedia.org/wiki/RGB_color_model)). Both types of images can be represented as multidimensional arrays.\n",
    "\n",
    "_Note: image was taken by Erik Mclean and sourced from [Unsplash](https://unsplash.com/photos/BIheydot8Jw)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try loading the image into an array. We've hidden how this is done, but feel free to check out `utility/util.py` if you are curious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility.util import load_image, show_array_as_image\n",
    "\n",
    "image = load_image('utility/data/example-image.png')\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_array_as_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4.2\n",
    "\n",
    "**Do this!** Retrieve the shape of the array. \n",
    "\n",
    "*Note: This question is graded on more than public tests alone*\n",
    "\n",
    "_**Hint**: the property you are looking for has the same name as what you are looking for._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shape = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4bi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Write-up!** How do the dimensions of the array relate to the axes (height and width) of image? How were you able to tell?\n",
    "\n",
    "_**Hint**: Compare the shape of the array and the image itself._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Problem 4.3\n",
    "\n",
    "**Do this!** Compute the average intensity of each \"row\" of pixels in the image and store the values in `average_row_intensities`. Do the same for each \"column\" of pixels in the image and store the values in `average_column_intensities`. You should only use NumPy's vectorized operations. No loops!\n",
    "\n",
    "*Note: This question is graded on more than public tests alone*\n",
    "\n",
    "_**Hint**: Which axis do you want to perform the operation across? How many values do you expect to get from each operation? Are the shapes of the resulting arrays consistent with your expectations?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "average_row_intensities = ...\n",
    "average_column_intensities = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4ci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Let's try to get a better feel for what is going on. How would we find the darkest pixel in the image?\n",
    "\n",
    "**Do this!** Get the indicies of the row and column with smallest average value. Print these values (row first). _**Hint**: refer back to Lab 0._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Write-up!** Are these values consistent with the image? What is located at the pixel with these coordinates? Here is the image again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_array_as_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Problem 4.4\n",
    "\n",
    "Finally, let's try adjusting the brightness or [exposure](https://en.wikipedia.org/wiki/Exposure_(photography)) of the image. Remember that the `image` is represented as an array containing pixel intensities, where darker colors have values smaller than lighter colors. Thus, we can make an image \"brighter\" by making the pixel intensity values larger.\n",
    "\n",
    "**Do this!** Make the image **half as bright** and store the new image in `darker_image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "darker_image = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's look at our new image\n",
    "show_array_as_image(darker_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're done! Please follow the directions below **carefully** to make sure you generate your finished copy of the homework correctly, and then upload the .zip file to Gradescope.\n",
    "\n",
    "Your workflow should be:\n",
    " - Run all cells in the notebook **EXCEPT** the export cell\n",
    " - Save the file\n",
    " - Run the export cell and download your zip file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "otter": {
   "tests": {
    "q2a": {
     "name": "q2a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(shorter_string) == len(my_string) - 4\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> new_list == [2,3,4]\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2c": {
     "name": "q2c",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> fizzbuzz(8) == [1, 2, 'Fizz', 4, 'Buzz', 'Fizz', 7, 8]\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> fizzbuzz(3) == [1, 2, 'Fizz']\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> fizzbuzz(15)[14] == 'FizzBuzz'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2d": {
     "name": "q2d",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> hailstone(11) == [11, 34, 17, 52, 26, 13, 40, 20, 10, 5, 16, 8, 4, 2, 1]\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> hailstone(10) == [10, 5, 16, 8, 4, 2, 1]\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2e": {
     "name": "q2e",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(soonest_grad_date[1], int)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(soonest_grad_date[0], str)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> soonest_grad_date[2]==2021\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> soonest_grad_date[1]==21\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> soonest_grad_date[0]==\"Jeff\"\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> generate_random_array(5).size == 5\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> isinstance(generate_random_array(20), np.ndarray)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> an_array = generate_random_array(100)\n>>> loop_sum(an_array) == sum(an_array)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4a": {
     "name": "q4a",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> ones_array.shape == (3,3,2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.sum(ones_array) == ones_array.size\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4bi": {
     "name": "q4bi",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> shape == (250, 374)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4ci": {
     "name": "q4ci",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(average_row_intensities.sum(), 205.15002) == True\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(average_column_intensities.sum(), 306.90482) == True\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4d": {
     "name": "q4d",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.all(darker_image < image)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
